# 大模型只会算数，为什么能“听懂人话”？（Embedding 到 RAG 的一张小地图）

我一直觉得这件事很神奇：

- 电脑只会处理数字。
- 我们说的是人话（里面有隐喻、双关、吐槽、潜台词）。
- 然后它们居然能聊起来。

所以我想画一张“小地图”，把这件事拆开看清楚：**文字是怎么变成“意思”的？Embedding 又在哪个环节登场？**

先放结论版流程图：

```
文字
  ↓  tokenizer（切成 token）
token IDs（数字）
  ↓  embedding table（查表）
一堆向量（每个 token 一个）
  ↓  transformer（注意力：互相“看”）
上下文向量（会变的）
  ↓  任务：生成 / 检索 / 分类 / …
```

下面我们按顺序走一遍。

---

## 1) 机器不直接读“字”，它读的是 token

你输入一句话，比如：

> 我爱苹果

模型的第一步不是“理解”，而是切片：把文本切成若干个 token，然后把每个 token 换成一个整数 ID。

（示意，不同模型的切法不同）

```
"我爱苹果"
  ↓ tokenizer
["我", "爱", "苹", "果"]
  ↓ lookup id
[23, 105, 998, 1004]
```

重点是：**到这里为止，只有数字，没有语义。**

`998` 并不“像”苹果，它只是一个编号。

---

## 2) Embedding：把编号变成坐标（但先别急，这坐标一开始是“死的”）

Embedding 最像什么？我觉得最像一个巨大的表格：每个 ID 对应一行向量。

```
ID      向量（例如 4096 维）
23   -> [0.12, -0.07, ...]
105  -> [0.03,  0.11, ...]
998  -> [-0.20, 0.04,  ...]
```

所以 Embedding 的第一个动作其实非常朴素：

- 拿到 `998`
- 去表里取第 998 行
- 复制出来

在这一刻，Embedding 还没有“上下文感知”。

也就是说：只要 token ID 一样，“苹果”的初始向量就一样。

这听起来就会出事，对吧？因为“苹果”可以是水果，也可以是公司。

---

## 3) “上下文感知”是怎么来的？Transformer：让 token 互相看一眼

真正让向量“活”起来的，是 Transformer 里的注意力机制。

我喜欢把它理解成：**句子里的每个 token 都会问一句：我该关心谁？**

比如：

> 苹果 发布 了 新 手机

当模型在更新“苹果”的向量时，它会去看“发布”“手机”等词，然后把这些信息按权重混进来。

可以想象成这张乱糟糟但有用的箭头图：

```
苹果  → 发布
苹果  → 手机
苹果  → 新
```

于是你会得到两个不同的“苹果”：

- “我吃了一个苹果”里的苹果，向量会更像【食物】那一片
- “苹果发布了新手机”里的苹果，向量会更像【公司】那一片

这里有个很关键的语言：**Embedding 有两种常见含义**

- 输入层 embedding：查表得到的“静态向量”
- Transformer 输出的 embedding（hidden state）：上下文混合后的“动态向量”

如果你在做检索/向量库，通常你要的是第二种（更有语义的那种）。

---

## 4) 为什么叫“多头注意力”？因为它不是一双眼睛，是一群小眼睛

如果让一个 token 只用“一种方式”去看别人，它容易顾此失彼。

比如同一句话里，它可能同时需要：

- 找语法结构（主谓宾）
- 找指代关系（it 到底指谁）
- 找关键词（这句在讲什么主题）

于是模型把注意力拆成很多个“头”（heads）。你可以把它当成很多组并行的小专家。

```
Head A：更关注语法关系
Head B：更关注指代
Head C：更关注短语边界
...
```

每个头各干各的，最后把结果拼起来，得到一个更丰富的向量。

我喜欢这个想法：**不是一个聪明的大脑，而是一堆有点偏执的小脑袋一起投票。**

---

## 5) “国王 - 男人 + 女人 = 女王”到底靠谱吗？

你可能见过这个经典例子：

> King - Man + Woman ≈ Queen

它在某些模型、某些关系上确实会成立。

但我会把它当成一个“演示用的魔术”，而不是“通用的工程工具”。

原因很简单：

- 语义不是积木，不是每个属性都能被干净地加上/减掉
- 向量空间也不是完美的欧几里得世界，它会被训练过程挤压变形

所以在真实工程里，想做“多条件查询”时，直接把向量相加经常会翻车。

更稳的做法是把“组合逻辑”交给语言模型本身：

- 让它把你的查询重写得更具体
- 或者先生成一段“可能的答案文本”，再对这段文本做 embedding（HyDE）

这听起来有点绕，但它的本质是：**用语言去组合语言，而不是用向量硬拼。**

---

## 6) 如果你在做向量数据库：一段文字的向量从哪来？

模型内部是一堆 token 向量：

```
token1 向量
token2 向量
token3 向量
...
```

但向量数据库希望你给它一个向量，代表“一段话”或“一个 chunk”。

所以你需要做 pooling（池化）：把一堆向量压成一个向量。

常见三种：

- Mean pooling：所有 token 向量取平均
- CLS token：用专门的汇总 token 代表全句（常见于 BERT 类）
- Last token：用最后一个 token 的向量当作整段（常见于自回归模型的某些用法）

再加一个现实问题：tokenizer 会把词拆开。

比如（示意）：

```
Unbelievable -> ["Un", "believ", "able"]
```

这会让“词”的边界变得模糊，所以我更倾向于把向量检索当成“粗筛”，然后配合：

- 关键词检索（专有名词、数字、型号）
- rerank（把 query 和候选段落放一起打分）

一句话：**混合检索经常比纯向量检索更抗翻车。**

---

## 7) 我最喜欢的解释：压缩即智能

最后留一个我很喜欢的视角：压缩。

当模型读了海量文本，它必须把这些信息压缩进有限的参数里。为了压缩得更好，它会被迫学会各种结构：

- 哪些词经常一起出现
- 哪些表达通常意味着同一件事
- 哪些写法是在转折、在强调、在讽刺

Embedding 可以理解成这张压缩地图里的一层：把语言折叠到一个高维空间里，让“相近的意思”离得更近。

下次你看到模型一句一句往外吐字时，可以把它想成：它在这张地图上做导航，然后把路径翻译回人类语言。
