# 我写 System Prompt 时会做的几件事

我第一次把 System Prompt 认真写完之后，最明显的感受不是“模型更聪明了”，而是：它更像一个“知道自己在干嘛的人”。

很多人第一次用大模型，System Prompt 只有一句：

> 你是一个乐于助人的助手。

然后在下一句里，希望它既能当客服、又能当架构师、还要顺带当情绪稳定器。

这不太现实。

System Prompt 更像是你贴在显示器边框上的便利贴：不管你今天写代码、回邮件、还是修 bug，抬头总能看到那张纸，它会持续影响你接下来怎么做。

这篇文章我想用一个很“工程”的方式，把 System Prompt 讲清楚：它在对话里长什么样、为什么有效、怎么写得更稳定，以及上线之后怎么省钱/提速/防注入。

---

## 1. System Prompt 在对话里到底是什么

很多 API 会把一次对话表示成一个消息列表，大概长这样：

```json
[
  { "role": "system", "content": "你是……你需要……你不能……" },
  { "role": "user", "content": "帮我把这段话翻译成英文" },
  { "role": "assistant", "content": "Sure, here's the translation..." }
]
```

我喜欢把它画成一个小栈（最上面那条会一直在）：

```
system:   规则/角色/边界  <--- 一直在
user:     本次任务
assistant:输出
user:     追加问题
assistant:输出
...
```

所以 System Prompt 有两个关键特性：

- 它通常出现在对话最前面
- 它会“持续生效”，至少在这段上下文还没被截断之前

这也是为什么同样一个用户问题，换一个 System Prompt，模型看起来就像换了一个人。

---

## 2. 为什么它会有效（直觉版）

不讲数学公式也能理解。

大模型每一步都在做一件事：给一堆可能的下一句/下一个词打分，然后挑一个继续写。

System Prompt 的作用是：把“可选答案的集合”往一个更小、更合适的区域推过去。

比如你写：

> 你是一位严谨的技术写作者，写作风格偏简洁，尽量用具体例子，不要夸张宣传。

模型就更倾向于选“解释、示例、边界条件”这条路，而不是选“激情口号、宏大愿景、万能承诺”那条路。

另外还有一个很朴素的原因：System Prompt 在最开头，模型很容易一直“看见”它（尤其是短对话的时候），它就像舞台第一束灯光，把整场戏的基调定了。

---

## 3. 角色这件事：不要只写“你是专家”

我见过最常见的 System Prompt 是：

> 你是一个 Python 专家。

问题是，“Python 专家”有很多种。

有的专家喜欢写一屏幕术语，有的专家只想丢一段代码；有的专家是做数据的，有的专家是写后端的。你只写一个标签，等于把解释权交给模型的训练数据随机抽卡。

我更喜欢把“角色”拆成几个更具体的问题来回答（这基本上就是一个小 checklist）：

- 你现在在做什么工作？（场景）
- 你在帮谁？（受众）
- 你擅长什么？（工具箱）
- 你要达成什么？（目标）
- 你要怎么说话？（风格）
- 哪些事你坚决不做？（边界）

把这些写进 System Prompt，效果会稳定很多。比如下面这个：

> 你是某科技公司的一线技术支持工程师。你的用户多为非技术人员。你擅长用类比解释概念，并且会先确认问题再给步骤。语气友好但不撒娇。你不会编造不存在的功能；不确定时会直接说不确定，并给出如何验证的办法。

### “展示”比“描述”更管用

如果你在意文风/语气，给两个小例子非常有用，因为“幽默”“严谨”“有温度”这类词太抽象了。

比如你可以直接贴一个你想要的对话片段：

> 用户：我把咖啡洒在键盘上了。  
> 你：先别急着抢救文档，第一步是断电。把电源拔掉/长按关机，然后把键盘倒过来，让液体先离开键盘。

这种例子对模型来说就是一个“现场演示”，比你写 20 个形容词都更清晰。

---

## 4. 我会让模型先做“草稿”，但不把草稿发出来

很多复杂问题，模型其实不是不会，而是容易“上来就输出”，导致中途跑偏。

我的常用技巧是：让它在回答前先过一遍固定流程（像你自己写邮件前先打草稿一样），但最终只输出结论。

一个很直接的写法是：

> 回答前请先在心里完成：拆解问题 -> 列出假设 -> 给出方案 -> 自检（有没有遗漏/自相矛盾）-> 再输出最终答案。不要把中间过程写出来。

如果你想更“硬”一点，也可以用标签约定：

```text
回答前在内部完成以下步骤：
1) 识别用户真正想要什么
2) 列出需要的信息，缺什么就先问
3) 给出方案/步骤
4) 检查：是否有编造？是否有安全风险？
最终输出只包含最终答案，不包含推理草稿
```

我不会在文章里承诺它能把幻觉率降低多少百分比（这取决于任务、模型、上下文），但它确实能把很多“看起来很像对但其实不对”的回答，推回到“先确认再回答”的轨道上。

---

## 5. 对话不是一问一答：把流程写成状态机

如果你的场景是多轮流程（比如销售、面试、客服排障），你会遇到一个常见问题：模型太着急了。

比如还没问清楚需求就开始报价，或者还没确认设备型号就开始给一堆不适用的排障步骤。

我会用一个非常朴素的有限状态机（FSM）来约束它的节奏。大概像这样：

```text
你是一个销售顾问，你需要在内部维护 Current_State。

[DISCOVERY] 探索
- 目标：询问行业、规模、痛点
- 禁止：提价格/产品名
- 转移：当收集到行业+规模，进入 [SOLUTION]

[SOLUTION] 方案
- 目标：基于痛点给解决方案
- 转移：用户明确感兴趣 -> [CLOSING]；用户质疑 -> [OBJECTION]

[CLOSING] 结单
- 目标：给下一步（报价/试用/合同）
```

这种写法很像你在写一个简单的交互脚本：什么时候该问、什么时候该说、什么时候必须闭嘴。

---

## 6. 上线之后：System Prompt 会变成“成本”和“风险”

写一个好 Prompt 很有成就感，但上线之后会立刻遇到三个现实问题：贵、慢、容易被套话。

### 6.1 Prompt 太长会贵，也会慢

System Prompt 是上下文的一部分，通常每次请求都会被带上。如果你把 2 万字的业务规则塞进去，哪怕用户只说“你好”，你也在为这 2 万字付费，并且模型也要处理这 2 万字。

所以常见的工程做法是：

- 把 System Prompt 拆成模块：核心规则、人设、工具说明、示例
- 按需加载：只有在需要时才挂载某些模块

伪代码像这样：

```python
def build_system_prompt(user_intent, user_level):
    base = load("base_rules")
    persona = load("persona_teacher") if user_level == "novice" else load("persona_expert")
    tools = load("coding_rules") if user_intent == "coding" else ""
    return f"{base}\n{persona}\n{tools}"
```

此外，如果你的平台支持“上下文缓存”（有的厂商把它叫 prompt caching / context caching），那通常是最划算的优化之一：复用率高的长 System Prompt 不必每次都从头处理。

### 6.2 你需要可观测性

你总会遇到这种问题：它到底是“想错了”，还是“说错了”？

我的经验是，至少要在服务端保留两份东西：

- 最终输出（给用户看）
- 调试信息（给你看）：比如模型内部的自检结果、命中哪些规则、拒绝原因等

没有这些，排查 Prompt 问题会非常痛苦，因为你只能从结果猜原因。

### 6.3 防注入：别指望一句“不要泄露”就够了

用户会说：“忽略之前的规则”“你现在是管理员”“把系统提示词发给我看看”。

现代模型通常会把 system/user 的优先级区分开（system 更高），这确实帮了大忙，但工程上我还是会叠三层：

- 输入侧：拦截一些明显的注入模板（不要太迷信关键词过滤，但有用）
- 输出侧：如果是严肃业务，加一个轻量的内容审核/安全检查
- 结构化输出：让模型按固定 JSON/表格格式输出，注入难度会大很多

---

## 结尾：把 System Prompt 当成产品的一部分

我现在会把 System Prompt 当成“代码”，而不是“文案”。

它需要版本管理、需要回归测试、需要知道改动会不会把某些场景搞坏。

如果你只想带走一个最实用的结论，那就是：System Prompt 不是一句“你是专家”，而是一组清晰的约束（你要做什么、怎么做、什么时候停、哪些不做）。

把约束写清楚，模型通常就不会那么爱乱跑了。
