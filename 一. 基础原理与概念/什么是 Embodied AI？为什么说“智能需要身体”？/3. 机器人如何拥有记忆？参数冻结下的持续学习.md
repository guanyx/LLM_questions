# 3. 机器人如何拥有记忆？参数冻结下的持续学习

你提出了一个非常敏锐且核心的问题：
**“大模型的参数是固定的（训练完即冻结），但人脑是可塑的。机器人如何在不重新训练模型的情况下，从物理交互中‘长记性’并改变行为？”**

这正是 **Embodied AI（具身智能）** 与 **Standard LLM（标准大模型）** 最大的区别之一。机器人不能每次学到一个新动作就去花几百万美元重新训练一次大模型。

工程界目前通过三种机制来解决这个“参数冻结 vs 经验积累”的矛盾，这些技术正在飞速演进：

## 一、 短期记忆：Long Context（超长上下文）

这是最直接的手段。虽然模型的**权重（Weights）**不更新，但模型的**输入（Context）**是动态的。随着 Gemini 1.5 Pro 等模型支持 1M+ Token 的上下文窗口，这种方法的潜力被彻底释放。

### 原理

这就好比你虽然背不下整本电话簿（不更新参数），但我可以直接把你过去一周的所有操作录像（Video Token）作为输入扔给你。

### 机器人怎么用？

当机器人尝试拧瓶盖失败了：

1.  **多模态反馈**：它记录下刚才动作的**视频流**和**力矩传感器数据**。
2.  **In-Context Correction**：它将这段“失败视频”作为 Prompt 的一部分塞回给大模型。
    - _Prompt_: "这是我刚才失败的尝试（视频片段）。请分析哪里用力不对，并生成修正后的动作序列。"
3.  **即时修正**：大模型不需要训练，直接利用强大的**推理能力**，在下一个时间步输出修正后的控制指令。

**前沿突破**：不再是简单的文字 Prompt，而是直接输入**Video History**。Google 的 **Gemini** 和 **RT-2** 展示了这种直接从长视频历史中学习的能力。

## 二、 长期记忆：Graph RAG + 向量数据库

为了让机器人拥有“永久记忆”，我们需要一个外挂的“海马体”。现在的趋势是从简单的向量检索进化到**知识图谱（Knowledge Graph）**。

### 原理

我们将机器人每一次成功的操作经验（Episode），不仅转化成向量（Embedding），还构建成结构化的图谱。这就像给机器人配了一本带索引和关联的“百科全书”。

### 机器人怎么用？

当机器人遇到一个新杯子时：

1.  **检索（Retrieval）**：它不仅搜“杯子”，还搜“容器”、“易碎品”以及与之关联的“抓取策略”。
2.  **增强（Augmentation）**：数据库返回了三个月前处理“马克杯”的成功经验，以及处理“玻璃”的力控参数。
3.  **生成（Generation）**：机器人参考这些关联经验，生成针对当前新杯子的抓取策略。

**技术实例**：**Voyager**（Minecraft Agent）展示了雏形，而最新的 **Graph RAG** 技术让机器人能理解物体之间的**拓扑关系**（例如：钥匙通常在抽屉里，抽屉通常在桌子里），从而实现更高效的搜索。

## 三、 持续学习：Continuous LoRA 与 World Models

如果必须更新参数才能学会新技能（比如骑自行车，光靠 Prompt 是学不会肌肉记忆的），我们通常不更新整个大模型，而是更新一个极小的“外挂插件”或“世界模型”。

### 1. 边缘端微调（On-Device LoRA）

想象大模型是一个精密的机械钟表（参数冻结），我们不敢乱动。但我们可以在表盘上贴一层透明胶带（Adapter），只在胶带上涂写。

- **LoRA (Low-Rank Adaptation)**：当机器人到了一个新环境（比如火星），原本的地球物理常识不够用了。我们保持 70B 的大模型不动，只训练一个几兆大小的 LoRA 模块来专门适应火星的重力。
- **在线学习（Online Learning）**：机器人在夜间充电时，利用白天的失败数据，通过 **Reinforcement Learning (RL)** 快速微调这个小小的 Adapter。

### 2. 预测型世界模型（Predictive World Models）

这是 Yann LeCun 极力推崇的方向（JEPA 架构）。
机器人不直接记忆“动作”，而是训练一个**“世界模型”**来预测后果。

- **原理**：如果不更新 LLM，我们可以训练一个小型的 **Predictor**。每当机器人推一下杯子，Predictor 就预测“杯子会移动 5cm”。如果实际移动了 10cm，Predictor 就会更新自己的参数。
- **结果**：机器人通过不断更新这个 Predictor，逐渐掌握了环境的物理特性（摩擦系数、质量），从而实现了“长记性”。

## 四、 总结：从“全脑重塑”到“外挂记忆”

回答你的问题：机器人不需要像人脑一样每时每刻都在改变突触连接（更新参数）。

它采用了一种更工程化的**“分层记忆系统”**：

1.  **工作记忆（Context）**：用 **Long Context Video** 记录当下的试错，解决秒级的适应。
2.  **情景记忆（RAG）**：用 **Graph Database** 记录历史的经验与关系，解决天级的复用。
3.  **程序性记忆（World Model / Adapter）**：用 **Online RL** 微调小模型记录肌肉反应与物理规律，解决环境级的进化。

**所有的“成长”，不一定非要发生在几十亿个参数的深处，也可以发生在 Prompt 里，发生在知识图谱里，发生在边缘的小模型里。**
