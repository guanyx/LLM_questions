# 7.1 如果我们重新训练 Tokenizer，预训练好的模型还能用吗？

在上一篇文章中，我们聊到了 BPE（Byte-Pair Encoding）分词器的原理，也发现了它的一些“先天不足”：
*   **数学差**：数字被切碎，导致模型难以理解位值。
*   **中文贵**：中文词表小，导致切分粒度细，浪费 Token 且上下文窗口变短。

作为一个有追求的工程师，你可能会立刻想到一个直觉的解决方案：
**“既然这个 Tokenizer 不好用，那我针对我的业务场景（比如中文数学题），重新训练一个完美的 Tokenizer 不就行了吗？”**

这是一个非常棒的想法，也是很多垂直领域大模型（Vertical LLMs）必须面对的第一道坎。但答案可能会让你心里一凉：**不能直接用。如果你换了 Tokenizer，之前那个花了几百万美元训练出来的模型权重，基本上就废了。**

这篇文章我们就来扒一扒这背后的原理，以及我们到底该怎么办。

---

## 一、 为什么不能直接换？（原理篇）

要理解为什么不能换，我们需要深入到模型的“第一层”和“最后一层”来看。

### 1. 模型的入口：Embedding 层
模型并不直接认识 Token ID（比如 `1024`）。在模型的第一层，有一个巨大的查找表（Lookup Table），叫做 **Embedding Matrix**。
它的形状是 `[词表大小, 向量维度]`。比如 Llama 2 的词表大小是 32,000，维度是 4096，那么这个矩阵就有 32,000 行。

*   **旧 Tokenizer**：`1024` 代表单词 `Apple`。模型已经学会了，当它看到第 1024 行向量时，代表的是一种红色的、好吃的水果。
*   **新 Tokenizer**：你重新训练后，`1024` 可能变成了汉字 `猫`。

如果你直接把新 Tokenizer 喂给旧模型，当你输入 `猫`（ID 1024）时，模型调用的却是 `Apple` 的向量。
**结果**：模型会感到精神错乱，它“看到”的是水果，你却让它输出动物的逻辑。这就是典型的**语义空间错位**。

### 2. 模型的出口：Output Head
在模型的最后一层，通常有一个分类头（Linear Layer），它的形状是 `[向量维度, 词表大小]`，用来预测下一个 Token 的概率。

这个输出层也是和旧词表一一对应的。
*   旧模型认为输出层第 500 个位置概率高，代表要输出 `the`。
*   新 Tokenizer 的第 500 个位置可能是 `的`。

**结论**：**Tokenizer 和模型的 Embedding 层及 Output 层是“血肉相连”的强绑定关系。换了 Tokenizer，就等于给大脑换了一套全新的神经编码，之前的记忆（权重）完全无法对应。**

---

## 二、 那我们该怎么办？（实战篇）

既然直接换不行，难道我们就只能忍受原版 Tokenizer 的缺陷吗？
当然不是。业界主要有两条路可以走：

### 方案一：从头预训练（Pre-training from scratch）
这是最硬核、最彻底，但也是最昂贵的方案。

*   **做法**：
    1.  收集海量的目标领域数据（比如纯中文、纯代码）。
    2.  在这个数据集上训练全新的 Tokenizer（比如词表大小设为 64k）。
    3.  初始化一个全新的模型结构。
    4.  **从零开始**训练模型权重。
*   **优点**：
    *   Tokenizer 与数据完美契合，效率极高。
    *   没有任何历史包袱，模型表现上限最高。
*   **缺点**：
    *   **贵！** 需要消耗数百万 GPU 小时的算力。
    *   放弃了开源模型已经学到的通用知识（逻辑推理、世界知识），一切从零学起。

**适用场景**：你有“钞能力”，且你的数据分布与通用模型差异极大（比如你是做基因序列分析的，文本全是 `ATCG`）。

### 方案二：词表扩充（Vocabulary Expansion）—— 高性价比之选
这是绝大多数中文 LLaMA 模型（如 Chinese-LLaMA）采用的方案。
它的核心逻辑是：**保留旧的，添加新的。**

*   **做法**：
    1.  **保留**原版 Llama 的 32k 词表（保证以前学到的英语能力不丢失）。
    2.  在中文语料上训练一个新 Tokenizer，筛选出 20k 个高频中文 Token。
    3.  **合并**：将这 20k 个新 Token 加到旧词表中，总词表变为 52k。
    4.  **调整模型结构**：
        *   将 Embedding 矩阵从 `[32000, 4096]` 扩容到 `[52000, 4096]`。
        *   将 Output 层也相应扩容。
    5.  **增量预训练（Continued Pre-training）**：
        *   旧的 32k 行参数保持不变（或微调）。
        *   **重点训练那新增的 20k 行参数**，让模型学会这些新汉字的语义。
*   **优点**：
    *   **省钱**：不需要从零开始，只需要在原模型基础上再训练一小段时间。
    *   **继承**：完美继承了原模型的强大逻辑和英语能力。
    *   **优化**：显著提升了中文的编码效率（一个汉字就是一个 Token，不用再切碎了）。

**适用场景**：你想基于 Llama/Mistral 等强大的开源底座，打造一个更懂中文（或特定领域）的模型。

---

## 三、 避坑指南：给初级工程师的建议

如果你在实际工作中遇到了“分词不好用”的问题，请遵循以下决策流程：

1.  **先别急着换**：
    大多数情况下，直接使用开源模型的原版 Tokenizer 是性价比最高的。虽然中文效率低一点，但现在的显存和推理速度已经很快了，这点损耗通常是可以接受的。

2.  **如果非要改，首选“扩词表”**：
    千万不要把原版词表删了，一定要用“增量”的方式。
    *   **关键点**：新增 Token 的 Embedding 初始化很重要。不要随机初始化！最好是用该汉字在原版 Tokenizer 中对应的字向量的平均值来初始化，能加速收敛。

3.  **微调（SFT）解决不了分词问题**：
    很多同学问：“我只做 LoRA 微调，能解决分词问题吗？”
    **不能。** 微调只是调整模型的“性格”，改变不了它“识字”的方式。如果 `1024` 被切碎了，微调一万次它还是碎的。想改分词，必须涉及到底层 Embedding 的调整，这通常属于“增量预训练”的范畴，比 SFT 要重得多。

---

## 结语

Tokenizer 是大模型的地基。地基一旦打好（预训练完成），上面的楼房（模型权重）就定型了。
想要修整地基，要么把楼推倒重盖（从头训练），要么在旁边扩建（词表扩充）。

对于绝大多数应用开发者来说，**“适应它”比“改变它”更重要**。理解它的脾气，用 Prompt 工程或后处理去弥补它的短板，往往是比重新训练更聪明的选择。
