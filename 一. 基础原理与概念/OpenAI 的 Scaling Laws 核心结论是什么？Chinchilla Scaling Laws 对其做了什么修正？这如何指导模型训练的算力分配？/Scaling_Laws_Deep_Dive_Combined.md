# 我终于把 Scaling Laws 想明白了（以及这跟你我有什么关系）

我很长一段时间都以为“大模型变强”是一件很玄学的事：你堆一堆卡，跑很多天，突然它就会写诗、写代码、讲冷笑话。

后来我发现，至少在“预训练”这件事上，大家其实在拧三个旋钮：

- 参数量（Parameters）：模型的“脑容量”
- 数据量（Tokens）：模型读过的“书页数”
- 训练算力（Compute）：你愿意让它读多久、算多久

Scaling Laws 想说的事情非常朴素：你把这三个旋钮往上拧，Loss 通常会按一个挺稳定的节奏下降（幂律关系那种稳定）。问题是：到底该先拧哪个？

这篇文章讲四件事：

- 为什么 2020 年大家都在拼命堆参数
- 为什么 2022 年 DeepMind 说“等下，你们数据不够”
- 为什么 Llama-3 又反过来“喂爆数据”也没崩
- 如果你是普通工程师，这些结论怎么落到日常工作里

---

## 1）OpenAI 的版本：先把模型做大

2020 年左右，OpenAI 做了很多实验，总结出一个很诱人的规律：只要你加算力、加数据、加参数，模型会稳定变好。

听起来像废话，但它的杀伤力在于“可预测”。

你可以在小模型上测一堆点，然后用这个规律外推：如果我把训练算力翻一倍，大概能下降多少 Loss？这对做预算的人来说太香了。

当时业界一个非常自然的选择是：先把参数旋钮拧大一点。

于是 GPT-3 出来了：

- 1750 亿参数
- 约 3000 亿 token 的训练数据

这有点像：买了一个超大书架，但书没塞满。很多人那时还没意识到“书架太大但书太少”会带来什么后果。

---

## 2）Chinchilla 的版本：你们模型都饿着

2022 年 DeepMind 做了一件我特别喜欢的事：他们拿同一笔训练预算（同一个 compute budget），认真比较了不同“参数-数据”配比的效果。

结论很直白：

- 给定同样的训练算力，最佳策略不是一味变大模型
- 更好的做法是：参数和 token 应该一起涨，保持一个比较均衡的比例

他们给了一个很出圈的数字：大约 1:20。

意思是：每 1 个参数，最好至少看 20 个 token。

你可以把它当成一种“饲养指南”：别给龙猫买豪华跑轮但不给粮。

他们还做了一个让人很难忽略的对比：

- Chinchilla：700 亿参数，读了 1.4 万亿 token
- GPT-3：1750 亿参数，读了 3000 亿 token

结果是：小一号但读得多的 Chinchilla，很多任务上比 GPT-3 强。

所以 Chinchilla 的核心修正其实不是“别做大模型”，而是：

- 算力有限时，别把大部分预算都花在参数上
- 把一部分预算挪去买更多、更好的 token

---

## 3）一个插曲：MoE 把“参数”这件事拆成两半

到这里我们说的都还像是在讲 Dense 模型：每次前向都把全部参数过一遍。

但 MoE（混合专家）把“参数”拆成了两个概念：

- 总参数（Total params）：你存起来的“全体专家”
- 激活参数（Active params）：每次推理真正算到的那一小撮专家

这会让你在工程上同时面对两种预算：

- 显存预算：你能不能把所有专家都装进去
- 算力预算：每次推理你愿意激活多少专家

所以从 MoE 开始，“参数越大越好”这句话就更不完整了：你得问清楚是总参数还是激活参数。

---

## 4）Llama-3：把 Chinchilla 的建议当成“起步价”

然后 Meta 训练 Llama-3 的时候，干了件看起来很叛逆的事。

按 1:20 的 Chinchilla 建议：

- 8B 参数的模型，读 1600 亿 token 左右就挺合理

但 Llama-3 8B 实际读了：

- 15 万亿 token（15T）
- 这大约是 1:1875

第一次看到这个比例我也愣了：这不是“过度训练”吗？不怕过拟合？

这里有两个非常关键的“时代差异”：

### 4.1 LLM 里的“数据多”不等于“反复刷同一套题”

传统机器学习里，我们经常拿一个小数据集刷几十上百个 epoch，这当然容易记住噪声。

但大模型预训练更像是“读不同的书”，而不是“把同一本书背 200 遍”。

如果你的 15T token 大多数是去重过的、分布很广的文本，模型想靠死记硬背来“取巧”其实没那么容易，它不得不学一些更通用的规律：语法、事实、写作模式、代码结构……

当然，前提非常苛刻：去重、清洗、质量控制得做到位。垃圾重复才是真正的过拟合加速器。

### 4.2 训练最优 vs 推理最优：你到底在省哪笔钱？

Chinchilla 讨论的主要是“训练最优”：用同样训练算力，怎么把 loss 压得更低。

但很多产品的成本大头并不在训练，而在推理：

- 训练：一次性大支出
- 推理：每次调用都要付钱，而且可能付很多年

如果你预计模型上线后会被调用亿万次，那你就会很愿意在训练阶段多花点钱，把小模型练到“非常能打”，因为它每次推理都更便宜。

我喜欢把它理解成：

- 训练像买车（一次性的大支出）
- 推理像每天开车的油费/电费（按次发生，越跑越多）

如果你每天都要跑很多“公里”，那在买车时多花点钱、买一辆更省油的车，长期就会更划算。

### 4.3 “顿悟”和“双重下降”是怎么回事（只讲直觉）

有些训练过程会出现很奇怪的现象：

- 训练集指标看起来早就很好了
- 但测试集就是不涨
- 再坚持训练一段时间，测试集突然开始明显上升

这类现象常被拿来形容为 Grokking（顿悟）。你不需要把它当成神秘学，把它当成“模型在内部重新组织了表示”就好。

Double Descent（双重下降）则是在更宏观层面提醒你：泛化误差的曲线并不总是你在课本里见到的那条 U 型，有时候会出现第二次下降。

你不需要记住这些名词，你只需要记住一个工程上很实用的结论：

- 在大模型这套世界里，“多训练一点”并不自动等于“会过拟合”
- 真正危险的是：低质量重复、数据污染、去重没做好

---

## 5）15T token 从哪来：合成数据不是“随便让模型写点东西”

好，现在我们承认数据很重要了。

但现实问题是：高质量人类文本快被挖得差不多了。

所以大家开始做合成数据（Synthetic Data）。然后很多人第一步就踩坑：

“给我生成 1000 条高质量数学题。”

结果通常是：

- 同质化：换汤不换药的小学应用题
- 缺深度：一眼看穿
- 还可能夹带幻觉

我见过更有效的几种“数据炼金术”，它们共同点是：不靠一句 prompt，靠流程。

### 5.1 Evol-Instruct：别让它从零开始，逼它改稿

Evol-Instruct 的思路特别像写作：好问题不是凭空想出来的，是改出来的。

比如你先有一个简单任务：

- “写一个贪吃蛇”

然后你要求它变异：

- 深度进化：不能用 Pygame，只能用原生 Curses
- 广度进化：用贪吃蛇解释交通调度

一句话总结：让模型扮演一个苛刻的甲方，不断加约束、加干扰项、加推理链。

### 5.2 Magpie：只给它对话开头，让它自己补全“用户问题”

Magpie 的点子很狡猾：很多对齐模型在训练时见过大量对话模板。

你只喂给它“用户要说话了”的开头，比如：

`<|start_header_id|>user<|end_header_id|>`

然后你停住。

它就会顺着训练分布，自己补全一个看起来挺像真实用户会问的问题。生成的多样性往往比硬写 prompt 更自然。

### 5.3 Back-Translation：拿“答案”反推“问题”

你有一堆好内容（论文、文档、代码注释），但缺的是好问题。

那就反过来：

- 给模型一段解释 Transformer 的文字
- 让它以“面试官”的身份设计一道考察深入理解的题

这类反推会稳定产出比“凭空出题”更靠谱的问题。

### 5.4 LLM-as-a-Judge：用另一个模型来挑刺

生成容易，验证难。

所以常见的流水线是：

1. Generator 生成题目和答案
2. Reviewer 用挑刺视角审核（严格、吹毛求疵那种）
3. Refiner 根据意见修正

如果你把这个流程做得很自动化，它就会像一个不停自我纠错的工厂。

---

## 6）职业焦虑：普通工程师还要不要学“预训练”？

我觉得答案是：理解它，但别把它当成你的主业。

从头预训练一个大模型更像是“造原子弹”：

- 资源门槛高（算力、数据、工程团队、基础设施）
- 经验门槛也高（分布式训练、容错、数据治理、评测体系）

但这不意味着普通工程师没戏。相反，我越来越觉得未来的大头在三件事：

### 6.1 Post-training：让模型真的听话、真的好用

基座模型懂很多，但不懂你的业务。

- SFT：用高质量指令数据把它推向正确的输出分布
- RLHF / DPO：把“用户更喜欢的答案”变成训练信号
- Evaluation：没有评测就没有进步，尤其在业务场景

### 6.2 推理优化：这是最容易产生真实 ROI 的地方

如果你能让推理成本下降 50%，你能在公司里瞬间拥有话语权。

常见方向：

- 量化：AWQ / GPTQ / SmoothQuant
- 推理框架：vLLM / TensorRT-LLM / TGI
- 让延迟更低、吞吐更高、显存更省

### 6.3 数据工程：数据是新的代码（而且更难写对）

去重、清洗、过滤、合成、审查、版本管理……这些会越来越像“主工程”。

你甚至可以把数据当成产品：有指标、有迭代、有回归测试。

---

## 结尾：三句话记住这篇文章

- Scaling Laws 让“堆参数/堆数据/堆算力”变成了一门可以算账的工程学
- Chinchilla 提醒我们：别让模型饿着，参数和数据要更平衡
- Llama-3 提醒我们：如果推理调用量巨大，把小模型训练到极致可能更划算
