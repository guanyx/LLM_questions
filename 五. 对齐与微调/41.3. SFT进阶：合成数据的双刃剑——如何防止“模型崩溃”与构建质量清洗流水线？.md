# SFT 进阶：合成数据的双刃剑——如何防止“模型崩溃”与构建质量清洗流水线？

## “近亲繁殖”的危机

在 SFT 的前沿探索中，“AI 教 AI”（使用合成数据）已经成为了行业标准。Llama 3、DeepSeek 等顶尖模型都证明了高质量合成数据的威力。

然而，这背后隐藏着一个巨大的风险：**模型崩溃（Model Collapse）**。
如果 Teacher Model 产生了幻觉，Student Model 照单全收，经过几轮迭代后，模型的输出分布会逐渐偏离真实世界，变得越来越疯狂和单一。就像近亲繁殖会导致基因缺陷一样，AI 只能从 AI 生成的数据中学习，最终会导致智力退化。

对于中级 AI 工程师来说，**生成数据只是第一步，清洗和验证数据才是拉开差距的关键。**

---

## 一、 为什么合成数据需要清洗？

很多人误以为 GPT-4 生成的数据就是完美的。其实不然，Teacher Model 生成的数据通常包含以下噪音：

1.  **事实性幻觉**：一本正经地胡编乱造。
2.  **逻辑中断**：推理链条（CoT）中间断裂，但最后蒙对了答案。
3.  **格式错误**：JSON 缺个括号，或者 Markdown 渲染失败。
4.  **同质化严重**：生成的句式千篇一律，缺乏多样性。

如果直接拿这些数据去微调，Student Model 学到的不仅是知识，还有“如何自信地胡说八道”。

---

## 二、 工业级的数据清洗流水线（Data Pipeline）

构建高质量 SFT 数据集，需要建立一套自动化的清洗流水线。以下是目前业界主流的 **“漏斗式”清洗方案**，结合了 2024-2025 年的最新技术：

### 1. 规则过滤（Rule-based Filtering）—— 第一道防线

这是成本最低、速度最快的方法，能过滤掉 30%-50% 的低质量数据。

- **长度过滤**：剔除过短（没信息量）或过长（可能是重复输出）的样本。
- **关键词过滤**：剔除包含“作为 AI 语言模型”、“我无法回答”等拒答词的样本。
- **格式校验**：如果任务要求输出 JSON，直接用代码 parse 一下，解析失败的直接丢弃。

### 2. 逻辑一致性校验（Consistency Check）—— 核心环节

对于理科题（数学、代码），我们可以利用**执行反馈**来验证。

- **代码题（Execution-based）**：Teacher Model 生成代码后，直接在沙箱（Sandbox）里跑单元测试。跑通了就是好数据，跑不通直接丢掉。
- **数学题（Self-Consistency）**：让模型用 3 种不同的推理路径（Reasoning Paths）做同一道题。如果 3 次得出的最终答案一致，说明这条数据质量很高；如果答案五花八门，说明模型自己在瞎蒙，直接丢弃。

### 3. AI 批判与修正（Critique & Refine）—— 前沿玩法

不仅仅是简单的过滤，而是**变废为宝**。

- **Critique（批判）**：让 Teacher Model 自己检查生成的数据：“这个答案的逻辑有漏洞吗？”
- **Refine（修正）**：如果有漏洞，让它自己重写。这种 **Self-Correction** 产生的数据质量往往远高于一次生成的数据。

### 4. 难度与多样性控制（Difficulty & Diversity）

- **IFD 指标（Instruction Following Difficulty）**：不再只看困惑度，而是计算模型对指令的“惊奇度”。优先保留那些“模型觉得难但又能答对”的高价值样本。
- **InsTag（自动化打标）**：利用 LLM 给每条数据打上标签（如 #Python, #算法, #递归）。通过标签分布来平衡数据集，确保模型不偏科，而不是简单的随机采样。

---

## 三、 案例分析：DeepSeek-Coder 的清洗策略

DeepSeek-Coder 在代码微调领域的成功，很大程度上归功于其严苛的数据清洗流程：

1.  **去重**：在文件级和项目级都进行了去重。
2.  **依赖分析**：剔除了那些依赖缺失、无法编译的代码片段。
3.  **质量模型**：训练了一个分类器，专门识别代码的可读性和模块化程度。

**结果**：清洗后的数据量只有原始数据的 20%，但微调出的模型性能却提升了 50%。**Less is More** 在这里得到了完美验证。

---

## 四、 总结：从 Data-Centric AI 视角看 SFT

作为工程师，你的关注点应该从“调整超参数（Learning Rate, Epoch）”转移到“打磨数据（Data Engineering）”上来。

**SFT 的本质是数据工程。**

不要迷信 Teacher Model 的权威。构建一套**自动化、多层次、闭环**的数据清洗流水线，引入 **Critique** 和 **IFD** 等前沿评估手段，确保每一条喂给 Student Model 的数据都是经过严选的“营养餐”，这才是避免模型崩溃、实现 SFT 效果跃升的终极秘籍。
