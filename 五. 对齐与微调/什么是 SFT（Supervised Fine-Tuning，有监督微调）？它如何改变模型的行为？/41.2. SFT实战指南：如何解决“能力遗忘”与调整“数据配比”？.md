# SFT 实战指南：如何解决“能力遗忘”与调整“数据配比”？

## 一个真实的“翻车”现场

很多初级工程师在第一次做微调（SFT）时，经常会遇到这样一个场景：

> 你兴致勃勃地收集了 1 万条高质量的“医疗问答数据”，对 Llama 3 进行微调。
> 训练结束后，模型在医疗问题上表现神勇，仿佛一位老专家。
> 但当你随口问它：“写一个 Python 冒泡排序”时，它却开始胡言乱语，或者写出的代码语法错误百出。

这就是经典的**灾难性遗忘（Catastrophic Forgetting）**。你为了让模型学会医术，结果让它把大学学的编程和数学全忘了。

本文将深入探讨这个问题的核心——**数据配比（Data Mixture）**，并介绍 2024-2025 年最前沿的解决方案。

---

## 一、 为什么会遗忘？（对齐税的本质）

模型的大脑（参数）是有限的。SFT 的本质是**参数权重的重新分配**。

- **预训练阶段**：权重分布是为了覆盖所有领域的知识（通用能力）。
- **微调阶段**：如果只给垂直领域数据，梯度下降算法会疯狂地修改权重，使其**过拟合**到当前的垂直领域。

由于神经网络是高度关联的，修改权重的过程就像是在“拆东墙补西墙”。你为了优化医疗领域的 Loss，可能不小心破坏了负责逻辑推理或代码生成的神经元连接。

---

## 二、 黄金法则：Replay Buffer（数据回放）与合成数据

解决遗忘最有效、最通用的方法非常简单：**在训练数据中掺入一定比例的“通用预训练数据”。**

这被称为 **Replay Buffer（经验回放）**。就像是在给专科医生培训时，不仅要教医术，每天还要让他复习一下高中数学和英语，保持大脑的通用活性。

### 1. 掺什么数据？（通用能力的锚点）

你需要准备一个“通用保活数据集”，通常包含以下几类：

- **通用对话（General Chat）**：保持流畅的对话能力。
- **逻辑推理（GSM8K / Math）**：这是模型智商的底座，最容易被遗忘，必须重点保护。
- **代码（Code）**：代码能力代表了严密的逻辑，即使你的应用不写代码，保留代码数据也有助于提升逻辑能力。

**前沿趋势（Synthetic Replay）：**
现在的趋势不再是简单地回放旧数据，而是**使用合成数据**。
例如，用 GPT-4 生成与你垂直领域相关的通用逻辑题。这比单纯回放不相关的 Wikipedia 数据效果更好，被称为 **Evol-Instruct**。

### 2. 掺多少？（黄金配比建议）

虽然没有放之四海而皆准的公式，但业界（如 OpenAI, DeepSeek, Llama 团队）有一些经验法则：

- **激进派（10:1）**：

  - 如果你极其看重垂直领域表现，且不介意通用能力下降。
  - **配比**：10 份垂直数据 : 1 份通用数据。
  - **后果**：模型变成“偏科生”。

- **稳健派（1:1 ~ 1:5）**：**（推荐）**
  - 这是目前最主流的做法。为了保持模型的通用智商（Reasoning），通用数据的量级往往要**等于甚至大于**垂直数据。
  - **配比**：1 份垂直数据 : 1~5 份通用数据。
  - **逻辑**：垂直数据负责“引导方向”，通用数据负责“保持智商”。

**实战技巧**：如果你只有 1 万条医疗数据，你可以从开源数据集（如 UltraChat, ShareGPT, SlimPajama）中随机抽取 2 万条通用数据混进去一起练。

---

## 三、 进阶技巧：Model Merging 与 Packing

除了调整数据配比，2024 年兴起了一些更酷的技术手段。

### 1. Model Merging（模型融合）：事后补救的黑魔法

如果你已经训练好了一个垂直模型，发现它遗忘了通用能力，怎么办？重新训练太贵了。

- **做法**：使用 **Spherical Linear Interpolation (SLERP)** 等算法，将你的微调模型（SFT Model）与原始底座模型（Base Model）进行权重融合。
- **效果**：`New_Model = 0.7 * SFT_Model + 0.3 * Base_Model`。这通常能奇迹般地找回丢失的通用能力，同时保留大部分垂直能力。这是目前 HuggingFace 上各种“魔改模型”的常规操作。

### 2. NEFTune（噪声嵌入微调）

- **原理**：在 Embedding 层加入随机噪声。
- **效果**：这相当于一种正则化手段，防止模型对训练数据过拟合。实验证明，NEFTune 能在提升对话质量的同时，显著减少对原有能力的遗忘。

### 3. 使用 LoRA（低秩适应）而非全量微调

- **原理**：LoRA 冻结了模型的主干参数，只训练外挂的旁路参数（Adapter）。
- **优势**：由于主干参数没动，模型原本的“通用知识库”被完整保留了下来。虽然 LoRA 在某些极端任务上的上限可能不如全量微调，但在**抗遗忘**方面具有天然优势。

---

## 四、 总结：微调是一门平衡的艺术

做 SFT 不仅仅是“把数据喂进去”那么简单。它更像是在调鸡尾酒：

- **垂直数据**是基酒，决定了模型的风味（医疗、法律、金融）。
- **通用数据**是苏打水，决定了模型的口感和易饮度（智商、逻辑、通用性）。
- **Model Merging** 是最后的调味装饰，能挽救一杯调失败的酒。

**给初级工程师的建议：**
永远不要只用垂直数据进行微调。从第一天开始，就建立你的 **“通用保活数据集（Anchor Dataset）”**，并在每次微调时都按 **1:1** 或 **1:2** 的比例掺入。如果实在不行，学会用 **Model Merging** 来兜底。
