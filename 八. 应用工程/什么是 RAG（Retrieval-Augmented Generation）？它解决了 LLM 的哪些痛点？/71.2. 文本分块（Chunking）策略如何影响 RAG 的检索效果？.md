# 73. 文本分块（Chunking）策略如何影响 RAG 的检索效果？

在 RAG 系统中，很多人只关注**“换个更强的模型”**或者**“换个更好的向量数据库”**，却忽略了最基础的一步：**怎么切数据（Chunking）**。

**Garbage In, Garbage Out。** 如果切分策略很烂，把完整的逻辑切得支离破碎，那么再强的 Embedding 模型也救不了你。

---

## 1. 为什么“切”这么重要？

LLM 的上下文窗口是有限的（虽然在变大，但还是昂贵）。我们不能把整本书都塞进去，所以必须把书切成小块（Chunk）。

- **切坏了的后果**：
  - **断章取义**：把“公司**不**允许报销打车费”切成了“公司...允许报销打车费”（语义反转）。
  - **上下文丢失**：问题是“它的原理是什么？”，但对应的 Chunk 里只有“原理是...”这一半，另一半在下一个 Chunk 里，检索时没把下一个捞出来。

---

## 2. 常见的切分策略（从青铜到王者）

### (1) 固定大小切分（Fixed-Size Chunking）—— 青铜段位

这是最简单粗暴的方法。设定一个窗口大小（比如 500 tokens），每 500 个就切一刀。

- **优点**：代码只需一行，计算开销极低。
- **缺点**：**毫无人性**。它会无情地切断句子、段落甚至单词。
- **补救措施**：引入**重叠（Overlap）**。比如每切 500 个词，往回倒退 50 个词再开始切下一块。这 50 个词的“缓冲区”能稍微缓解边缘信息的丢失。

### (2) 递归字符切分（Recursive Character Chunking）—— 黄金段位

这是 LangChain 等框架的默认策略。它不是硬切，而是**“看眼色行事”**。

- **逻辑**：尝试按 `\n\n`（段落）切 -> 切不动就按 `\n`（句子）切 -> 还不行就按空格切。
- **优点**：尽可能保留了段落和句子的完整性，符合人类的阅读习惯。

### (3) 语义切分（Semantic Chunking）—— 王者段位

不再按字数切，而是按**“意思”**切。

- **原理**：利用 Embedding 模型计算相邻两句话的相似度。如果前一句话在讲“苹果的财报”，后一句话突然讲“香蕉的产地”，相似度骤降，系统就在这里**狠狠切一刀**。
- **优点**：保证了每个 Chunk 内部的**语义纯度**，检索召回率通常最高。
- **缺点**：计算成本高，需要对全文先做一遍 Embedding。

### (4) Agentic Chunking（智能体切分）—— 2025 新贵

这是目前最前沿的思路。不再用死规则，而是让一个小 LLM（Agent）像人一样去读文章。

- **原理**：让 Agent 边读边思考：“这句话和上一句是同一个主题吗？如果是，合并；如果不是，切开。”
- **优点**：能处理极其复杂的逻辑嵌套，甚至能识别出“引用”、“反讽”等隐晦的语义边界。
- **缺点**：慢，贵。适合对精度要求极高的场景（如法律文书分析）。

---

## 3. Chunk Size：多大才合适？

这是一个经典的 **Trade-off（权衡）**：

- **小 Chunk（比如 128 tokens）**：
  - **优点**：**精准**。检索出来的就是你要的那句话，噪音少。
  - **缺点**：**缺乏语境**。可能只有“他同意了”，但不知道“他”是谁，同意了什么。
- **大 Chunk（比如 1024 tokens）**：
  - **优点**：**语境丰富**。能看到前因后果。
  - **缺点**：**噪音大**。包含了很多无关信息，可能会干扰 LLM 的注意力（Lost in the Middle）。

**最佳实践（2025 版）**：
不要只存一种。
**1. “小块索引，大块召回（Small-to-Big / Parent Document Retrieval）”**。

- 索引时用**小 Chunk**（便于精准匹配向量）。
- 检索到小 Chunk 后，通过 ID 找到它所属的**父文档（Parent Document）**或**周围的大窗口**，把内容扩充后再喂给 LLM。

**2. 上下文感知切分（Context-Aware Chunking）**。

- **痛点**：一个切片里写着“公司收入增长 50%”，但没写是哪家公司（主语在上一页）。
- **解法**：在切分时，利用 LLM 为每个 Chunk **生成一个简短的上下文摘要（Summary）**并附在头部。这样即使 Chunk 被单独捞出来，它也知道自己属于“Apple 2024 Q4 财报”。

---

## 4. 总结

不要小看切分。在 RAG 调优中，**调整 Chunking 策略带来的提升，往往比微调模型要大得多且便宜得多。**

- 对于结构化文档（Markdown/HTML）：**基于结构的切分**（按标题头切）是首选。
- 对于长文本叙事：**语义切分**效果最好。
- 永远记得加 **Overlap**（通常设为 10%-20%）。
