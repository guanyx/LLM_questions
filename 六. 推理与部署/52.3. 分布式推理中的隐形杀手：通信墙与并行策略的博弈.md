# 52.3. 分布式推理中的隐形杀手：通信墙与并行策略的博弈

当我们把目光从 7B、13B 这种可以在单张 4090 或 A100 上跑起来的“小”模型，转向 70B 甚至 405B 的庞然大物时，规则彻底变了。

单卡显存装不下，必须**加卡**。
初学者往往认为：“一张卡跑得慢，我加四张卡，速度是不是就能快四倍？”
**答案通常是残酷的：不仅不会快四倍，甚至可能更慢。**

这背后隐藏着分布式系统的终极 Boss —— **通信墙（Communication Wall）**。作为高级架构师，我们需要在算力、显存和通信之间，进行一场精密的博弈。

---

## 一、 为什么要分布式？不仅仅是“装不下”

使用多张显卡（分布式推理）主要解决两个问题：
1.  **显存容量（Memory Capacity）**：模型太大，单卡放不下。比如 Llama-3-405B，光参数就需要 800GB+ 显存，至少需要 16 张 A100-80G。
2.  **显存带宽（Memory Bandwidth）**：单卡带宽有限。多卡并行可以让多块显存同时搬运数据，理论上能提升 Decode 阶段的速度。

但是，**天下没有免费的午餐**。多卡之间必须频繁交换数据，才能完成一次计算。这个“交换数据”的时间，就是我们付出的代价。

---

## 二、 两种主流的“分工模式”

为了让多张卡合作，业界主要有两种切分模型的方法，它们对延迟和吞吐量的影响截然不同。

### 1. Tensor Parallelism (TP)：多人共做一道题
*   **原理**：把模型的每一层（Layer）的大矩阵切开，分给不同的卡计算。比如一个矩阵乘法，卡1算上半部分，卡2算下半部分，最后把结果拼起来。
*   **特点**：
    *   **延迟（Latency）极低**：所有卡同时干活，算力聚合了，带宽也聚合了。理想情况下，TP=4 可以让推理速度提升接近 4 倍。
    *   **通信极频**：每算完一层（Layer）甚至一个操作，所有卡就必须停下来“对答案”（All-Reduce 通信）。LLM 有几十上百层，意味着每生成一个 Token，就要进行几十次通信。
*   **适用场景**：**对延迟极其敏感的在线服务**。
*   **限制**：由于通信太频繁，TP 通常只能在**单机内部（Intra-node）** 使用，依赖 NVLink 这种超高速互联。一旦跨机（走以太网或 IB），通信延迟会瞬间吃掉所有加速红利。

### 2. Pipeline Parallelism (PP)：流水线作业
*   **原理**：按层切分。卡1负责第 1-10 层，卡2负责 11-20 层……卡1算完扔给卡2。
*   **特点**：
    *   **吞吐量（Throughput）高**：可以通过加大 Batch Size 让流水线填满。
    *   **延迟（Latency）高**：对于单个请求来说，它必须走完所有卡的旅程，没有任何加速（甚至因为传输慢了）。而且如果流水线没填满，会有大量的“气泡”（Bubble）导致显卡空转。
*   **通信较少**：只在切分点传输中间结果。
*   **适用场景**：**超大模型跨机部署**，或者**离线批处理**。

---

## 三、 通信墙：当网线成为瓶颈

在分布式推理中，我们最害怕遇到的情况是：**计算 1ms，通信 2ms**。
这就是“通信墙”。

### 1. 收益递减效应
当你把 TP 从 2 增加到 4，速度可能提升显著。但从 4 增加到 8，提升可能变小。如果你尝试跨机 TP（比如 2 台机器各 4 张卡），速度可能会出现**断崖式下跌**。
因为网络传输速度（即使是 400Gbps 的 IB 网络）相比于卡内显存速度和 NVLink，依然慢了一个数量级。

### 2. Sweet Spot（最佳平衡点）
高级架构师的核心工作，就是寻找那个 Sweet Spot：
*   **能用 TP 绝不用 PP**：只要单机能装下，优先用 TP，因为延迟最低。
*   **单机装不下怎么办？**：先在单机内把 TP 拉满（比如 TP=8），然后跨机使用 PP。即 **TP + PP 混合并行**。

---

## 四、 前沿探讨：Speculative Decoding 的尴尬

在单卡场景下，**推测解码（Speculative Decoding）** 是加速神器（用小模型猜，大模型改）。
但在分布式场景下，它面临着尴尬的局面：

*   **验证成本高**：大模型验证小模型的猜测时，依然需要运行一次完整的分布式推理。
*   **通信拖后腿**：如果猜测错误需要回滚，或者验证过程本身的通信开销过大，可能会导致“猜对了没快多少，猜错了反而更慢”。

因此，在分布式环境部署推测解码，需要极高精度的“草稿模型（Draft Model）”和极致优化的通信算子，否则得不偿失。

---

## 五、 总结

从单卡到分布式，不仅仅是硬件的堆砌，更是架构的重构。

*   **初级工程师**看算力（TFLOPS）。
*   **中级工程师**看带宽（Bandwidth）。
*   **高级工程师**看**拓扑（Topology）与通信（Communication）**。

在设计 70B+ 模型的推理系统时，请记住：**显卡之间的距离（NVLink vs PCIe vs Ethernet），往往比显卡本身的性能更决定成败。**
