# 23.3 数据配比（Data Mixing）的艺术：从静态混合到动态课程学习

清洗和去重只是为了得到“干净的食材”，但要煮出一道“满汉全席”（高性能大模型），关键在于**食材的配比**和**上菜的顺序**。

对于高级 AI 工程师而言，我们不再满足于“把脏数据洗干净”，而是开始思考一个更深层的问题：**在数万亿 Token 的训练过程中，Wikipedia、GitHub 代码、ArXiv 论文和网页数据，到底该按什么比例混合？这个比例是否应该随着训练进程而动态变化？**

本文将探讨数据配比（Data Mixing）的演进，从凭感觉的“炼丹”，走向基于 Loss 驱动的“科学”。

---

## 一、 静态配比：经验主义的“炼丹术”

在 GPT-3 和 PaLM 的早期时代，数据配比主要依靠工程师的直觉和经验。

### 1. 经典配方
一个典型的通用大模型配方可能长这样：
*   **Common Crawl (网页)**: 60% —— 提供广泛的世界知识，但噪声大。
*   **WebText (高质量网页)**: 20% —— 提升语言流畅度。
*   **Books (书籍)**: 10% —— 提供长文本和叙事逻辑。
*   **GitHub (代码)**: 5% —— 提升逻辑推理能力（CoT）。
*   **Wikipedia (百科)**: 5% —— 提供高密度事实知识。

### 2. 局限性
*   **拍脑袋**：为什么是 60% 而不是 50%？很难解释。
*   **领域冲突**：代码数据太多可能会损害自然语言的流畅性；网页数据太多可能会导致模型产生幻觉。
*   **静态僵化**：模型在训练初期可能需要简单的语法知识，后期需要复杂的逻辑推理，但静态配比全程不变，无法适应模型的成长需求。

---

## 二、 动态课程学习（Curriculum Learning）：从小学到大学

人类的学习过程是循序渐进的：先学识字（简单），再学造句，最后写论文（复杂）。大模型训练也应如此。

### 1. 简单优先策略
*   **Early Stage**: 喂给模型简单的、高质量的数据（如 Wikipedia、教科书）。让模型快速收敛，建立基础的世界观。
*   **Late Stage**: 逐渐加入复杂的、噪声稍大的网页数据（Common Crawl）。提升模型的鲁棒性和泛化能力。

### 2. 技能特定策略
*   **Code-Switching**: 在训练的中后期，突然增加代码数据的权重。研究发现，代码训练不仅能写代码，还能显著提升模型的**思维链（Chain-of-Thought）**推理能力。
*   **Long-Context Fine-tuning**: 在预训练的最后阶段（例如最后 10% 的 Token），将序列长度从 4k 拉长到 32k，专门喂长文本，让模型“适应”长窗口。

---

## 三、 DoReMi：基于 Loss 的自动化配比

Google 提出的 **DoReMi (Domain Reweighting with Minimax Optimization)** 算法，试图用数学方法解决配比问题，而不是靠猜。

### 1. 核心思想
**“以小博大”**。先训练一个小的代理模型（Proxy Model），用它来探索不同数据配比下的 Loss 变化，找到最优解，然后迁移给大模型。

### 2. 工作流程
1.  **Reference Run**: 先用均匀分布的数据训练一个小模型，记录它在各个领域（Domain）上的 Validation Loss。
2.  **Proxy Training**: 训练另一个小模型，使用**Group Distributionally Robust Optimization (Group DRO)** 算法。简单说，就是**哪个领域的 Loss 降得慢（最难学），就自动增加该领域的数据权重**。
3.  **Upscaling**: 将小模型摸索出来的“最优权重”，直接应用到几十 B 参数的大模型训练中。

### 3. 结果
实验表明，DoReMi 找到的配比，能让大模型在相同的训练步数下，Perplexity 显著降低，训练效率提升 2.6 倍。

---

## 四、 持续学习中的“灾难性遗忘”与重放（Replay）

当我们动态调整数据分布时，面临的最大风险是**灾难性遗忘（Catastrophic Forgetting）**。比如，后期为了加强代码能力，大幅增加 GitHub 数据，结果模型把之前学的英语语法忘光了。

### 解决方案：数据重放（Data Replay）
*   **机制**：无论当前阶段重点训练什么领域，都要始终保留一小部分（比如 1% - 5%）的“通用高质量数据”（如 Wikipedia + Books）作为**锚点（Anchor）**。
*   **作用**：这就像复习。即使在攻克高数难题，也要偶尔背背单词，保持基础能力的活性。

---

## 五、 总结

从静态配比到动态课程学习，反映了我们对大模型训练认知的深化：

1.  **数据非等价**：1 Token 的代码 $\neq$ 1 Token 的网页。
2.  **动态适应**：模型在不同训练阶段对数据的“胃口”是不同的。
3.  **自动化寻优**：未来的方向一定是像 DoReMi 这样，由算法自动决定“今天吃什么”，而不是由人类工程师手动写配置文件。

高级工程师的价值，就在于构建这样一套**自适应的数据供给系统**，让模型“吃得好，长得快”。
