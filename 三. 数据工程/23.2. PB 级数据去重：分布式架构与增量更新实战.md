# 23.2 PB 级数据去重：分布式架构与增量更新实战

对于中级 AI 工程师而言，理解 MinHash 的数学原理只是第一步。当数据规模从几百 GB 膨胀到 PB 级别（如 Common Crawl）时，真正的挑战才刚刚开始：**计算复杂度爆炸、内存溢出、Shuffle 导致的网卡打满**。

本文将从工程落地的角度，剖析如何在分布式系统（Spark/Ray）中构建高效的去重流水线，并解决最棘手的“增量更新”问题。

---

## 一、 核心挑战：规模改变一切

假设我们有 100 亿个文档。如果使用暴力两两对比（O(N²)），计算次数是 $10^{20}$ 次，哪怕用地球上所有的 GPU 也要算到地老天荒。

即使使用了 MinHash + LSH（局部敏感哈希）将复杂度降为 O(N)，在 PB 级数据下，单纯的计算开销依然巨大。因此，工业界的通用解法是：**漏斗型分层架构（The Funnel Architecture）**。

---

## 二、 架构设计：漏斗型分层去重

不要一上来就跑 MinHash。MinHash 计算签名（Signature）和哈希桶（Bucketing）是非常消耗 CPU 和 Shuffle 资源的。我们应该设计一个“漏斗”，让便宜的过滤器先挡在前面。

### 第一层：URL 去重（极低成本）
*   **逻辑**：如果是同一个 URL 抓取下来的页面，直接去重。
*   **实现**：维护一个 URL 的 Bloom Filter 或 HashSet。
*   **效果**：能过滤掉 30% 左右的显式重复。

### 第二层：精确去重（Exact Deduplication，低成本）
*   **逻辑**：内容完全一样的文本。
*   **实现**：计算全文的 SHA-256 或 MD5 哈希值。
*   **分布式技巧**：
    *   将 Hash 值作为 Key，进行 `groupBy` 或 `repartition`。
    *   在 Reduce 阶段，保留时间戳最新的那一条。
*   **效果**：又能过滤掉 30% - 40% 的数据（主要是转载、引用）。

### 第三层：模糊去重（Fuzzy Deduplication，高成本）
*   **逻辑**：MinHash + LSH。
*   **对象**：**只有通过了前两层的“幸存者”，才有资格进入这一层。** 这极大地减少了计算量。

---

## 三、 分布式实战：Spark/Ray 中的 LSH 优化

在 Spark 中实现 MinHash LSH，如果不注意细节，任务很容易挂掉（OOM）。

### 1. 避免全量 Shuffle
LSH 的核心是将相似的签名分到同一个“桶”（Bucket）里。
*   **错误做法**：直接对所有数据做全局 Shuffle。
*   **优化做法**：**分块计算（Blocking）**。虽然我们希望全局去重，但由于互联网数据的局部性（Locality），很多重复发生在一个 WARC 文件内部或同一个域名下。可以先在 Partition 内部做一次去重，减少传输到下游的数据量。

### 2. 解决数据倾斜（Data Skew）
某些“垃圾桶”可能会特别大。比如“Privacy Policy”或“Copyright”相关的哈希桶，可能包含数百万条数据。
*   **对策**：设置**桶大小上限（Bucket Size Threshold）**。如果一个桶里的文档数量超过 1000（举例），直接放弃对该桶的去重计算，或者采用随机采样。因为这么大的桶通常意味着极其通用的垃圾文本。

### 3. 广播小表
如果是将新数据与一个较小的精选数据集（如 Wikipedia）去重，不要 Shuffle 大表。使用 `Broadcast Variable` 将 MinHash 签名表广播到各个节点。

---

## 四、 终极难题：增量去重（Incremental Deduplication）

场景：你已经清洗好了 50TB 的历史数据（Base）。今天爬虫又抓回来了 1TB 的新数据（Delta）。
**问题**：如何判断这 1TB 新数据里，有没有和那 50TB 历史数据重复的？
**禁忌**：绝对不能把 51TB 数据合在一起重新跑一遍 MinHash！

### 解决方案：构建“去重索引”（Deduplication Index）

我们需要将去重变成一种“查询服务”，而不是“批处理任务”。

#### 1. 索引结构
我们需要持久化存储历史数据的指纹。
*   **存储选型**：Redis（高性能）、Cassandra（高吞吐）、或者专门的向量数据库（Vector DB）。
*   **Key-Value 设计**：
    *   **Key**: LSH 的 Band Hash 值（即桶号）。
    *   **Value**: 该桶对应的文档 ID 列表。

#### 2. 增量流程
1.  **计算新指纹**：对 1TB 新数据计算 MinHash 签名和 LSH Band Hash。
2.  **查库（Query）**：拿着新数据的 Band Hash 去数据库里查。“有没有历史文档也掉进了这个桶？”
3.  **局部比对**：如果命中了，只把命中的历史文档 ID 拿出来，和新文档计算 Jaccard 相似度。
4.  **更新库**：如果确认不重复，将新文档的指纹写入数据库，变成“历史”的一部分。

#### 3. Bloom Filter 的妙用
为了进一步减少查库开销，可以在数据库前挡一层 **Bloom Filter**。
*   将所有历史数据的精确 Hash（SHA-256）存入 Bloom Filter。
*   新数据来时，先问 Bloom Filter：“我见没见过这个 Hash？”
    *   如果回答“没见过”，那就是新的（Bloom Filter 不漏阴）。
    *   如果回答“可能见过”，再去查库确认。

---

## 五、 总结

PB 级数据去重的核心不在于算法的精妙，而在于**架构的取舍**。

1.  **漏斗思维**：先廉价后昂贵，层层剥离。
2.  **索引思维**：从“批处理”转向“检索”，利用 KV 存储解决增量问题。
3.  **防倾斜**：时刻警惕分布式系统中的热点桶。

掌握了这些，你才能从“会写代码”进阶为“能搞定大模型基础设施”的 AI 工程师。
