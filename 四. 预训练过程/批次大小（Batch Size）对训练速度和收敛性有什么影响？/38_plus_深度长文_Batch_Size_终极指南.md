# Batch Size：一个看似无聊的数字，为什么总能把训练搞崩？

我很喜欢这种问题：表面上是个“把显存填满”的参数，实际上牵扯到硬件、优化、泛化、甚至一些看起来像物理学的东西。

---

## 我们到底在讨论什么？

Batch Size 说的是：一次拿多少数据来算梯度。

但训练里有两种“速度”，经常被混在一起说：

- **吞吐（硬件速度）**：每秒处理多少 token / 图片？GPU 喜欢大矩阵，大 batch 通常更快。
- **收敛（算法速度）**：到同样的 loss / 指标，需要多少次参数更新？batch 变大，并不一定按比例变少更新步数。

我脑内的粗略图是这样的：

```
训练总耗时 ≈ 每步耗时 × 更新步数
         ≈ (受吞吐影响) × (受优化/噪声影响)
```

Batch Size 同时在动这两项，所以你一调它，就像同时拧了两颗旋钮：一个写着“快”，一个写着“好”。

---

## 小 batch 为什么经常更“稳”（或者更“会泛化”）？

有个很朴素的看法：小 batch 的梯度更“吵”，大 batch 的梯度更“安静”。

- **小 batch：吵**  
  每一步看见的数据不一样，方向会晃来晃去。神奇的是，这种晃动有时反而帮你避开“很窄很尖”的坏解（常说的 sharp minima），更容易落到“宽一点平一点”的区域（更可能泛化好）。

- **大 batch：安静**  
  梯度估计更精确，下降更像“直奔目标”。问题是：直奔的那个目标不一定是你想要的“宽盆地”，它可能是一个“训练集很爽、测试集翻车”的尖坑。

如果你只想记一句话：  
**batch 越大，梯度越像“真实平均”；batch 越小，梯度越像“带噪声的采样”。**

---

## 梯度累积：你以为你在用小 batch，其实你在用大 batch

这是最容易误会的一块。

训练里同时存在两个 batch：

- **物理 batch（micro-batch）**：每次 forward/backward 真正塞进显存的那一小坨。
- **逻辑 batch（global batch）**：优化器每次 `step()` 时“看到”的总样本量。

梯度累积做的事很简单：

```
for k in 1..acc_steps:
  loss = model(micro_batch)
  loss.backward()        # 梯度先攒着
optimizer.step()         # 最后再更新一次
optimizer.zero_grad()
```

它的效果更像是：

```
逻辑 batch = 物理 batch × 累积步数
```

所以，决定“噪声水平/泛化倾向”的，基本看的是 **逻辑 batch**，不是你一次塞进显存的那点 micro-batch。

### 这在 SFT 微调里尤其重要

很多人显存不够，物理 batch 只能设 1，然后为了“看起来很大模型”，把累积步数堆到 128。

直觉是：“我每次只看 1 条数据，应该很 noisy 吧？”

但优化器的视角是：“你 128 次才更新一次，那我看到的是一次非常平滑的平均梯度。”  
所以你得到的是**大 batch 的性格**，不是小 batch 的性格。

微调里想保留一点“好噪声”，一个更实用的策略是：**别把逻辑 batch 堆太大**。  
物理 batch=1 没关系，控制累积步数，让逻辑 batch 保持在 32/64/128 这种更常见的微调区间，会更符合直觉。

---

## 梯度累积 + BatchNorm：一个非常不礼貌的组合

如果你的模型里还有 BatchNorm（视觉 encoder 里很常见），这里有个坑：

**BatchNorm 的均值/方差，只用物理 batch 来算。**

它完全不知道你在做梯度累积。

于是就会出现一种“错位”：

- 统计量：基于物理 batch（可能只有 2 张图）
- 参数更新：基于逻辑 batch（可能相当于 128 张图的平均梯度）

物理 batch 太小时，BN 的统计量就会很抖，抖到足够离谱时，你会看到训练不稳定、loss 乱跳、甚至 NaN。

### 常见的解法（按我见过的频率排序）

- **微调预训练视觉模型**：冻结 BN（用已有 running mean/var，不再更新统计量）
- **从头训练但 batch 很小**：用 GroupNorm / LayerNorm 替代 BN
- **多卡训练**：用 SyncBN 让 BN “跨卡凑统计量”（代价是通信开销）

一句话版：**梯度累积能假装你有大 batch 的梯度，但 BN 统计量假装不了。**

---

## 当 batch 大到离谱：AdamW 为什么会“走不动”？

这部分更像“你遇到过就懂”的现象描述：

在超大规模预训练的后期，你可能会把 global batch 拉得非常大（为了压低梯度噪声、提高吞吐）。然后你会发现：

- loss 下降变慢，甚至像卡住
- 学习率一加就发散，不加又不动

一种常见解释是：一阶优化器（AdamW 这类）主要依赖“局部斜率信息”，在非常平滑、非常高维的地形上，效率会变差。于是大家开始认真考虑：

- **Shampoo / K-FAC 这类近似二阶/预条件方法**：更像在用“曲率信息”给梯度做矫正
- **Lion 这类更轻量的替代优化器**：用更简单的更新规则，反而在某些大 batch 场景更稳

我不想在这里装作能一锤定音地给出“哪个最好”。更靠谱的建议是：  
**如果你真的在做超大 batch 训练，把“优化器/预条件/学习率策略”当成第一优先级来研究，收益可能比继续堆 batch 更大。**

---

## 一个有点科幻但挺好玩的想法：SGD 的噪声可能是“重尾”的

最后这部分是“猜想/研究方向”，不是工程必修课。

传统上我们会把 SGD 的噪声当成高斯噪声（像布朗运动）。但一些研究指出：真实的梯度噪声可能是**重尾分布**，更像“多数时间小步走，偶尔突然跳很远”（莱维飞行）。

用这个视角看 batch size：

- 小 batch：更容易出现“偶尔的大跳”，可能更容易跨过势能壁垒，逃离尖坑
- 大 batch：噪声更像被平均成高斯，小跳为主，比较“守规矩”

顺着这个思路，有人会想：  
能不能物理上用超大 batch 把吞吐拉满，然后数学上人工注入结构化的重尾噪声，来“买回”小 batch 的泛化？

这听起来很诱人，但也有两大现实问题：

- 噪声不仅有“大小”，还有“方向结构”（各向异性），不是随便加点噪声就行
- 生成/估计这种结构化噪声可能也很贵

所以它更像一个值得关注的未来方向：**也许 batch size 的本质不是“多少样本”，而是“你想要什么样的随机性”。**

---

## 快速备忘录（我会贴在显示器旁边的那种）

| 你遇到的情况               | 最可能的关键点              | 一个实用动作                   |
| :------------------------- | :-------------------------- | :----------------------------- |
| 训练很慢，GPU 利用率不高   | batch 太小导致吞吐差        | 在显存允许下增大物理 batch     |
| 指标不稳、泛化差、像过拟合 | 逻辑 batch 太大、噪声被抹平 | 降低累积步数/降低 global batch |
| 用了梯度累积但 BN 崩了     | BN 只看物理 batch 的统计量  | 冻结 BN / 换 GN/LN / 用 SyncBN |
| 超大 batch 下 AdamW 不动   | 一阶优化器效率瓶颈          | 研究优化器/预条件/学习率策略   |

如果只留一句结论：  
**“Batch Size”不是一个旋钮，而是一组旋钮：吞吐、噪声、统计量、优化器假设，全都在跟着它一起动。**
