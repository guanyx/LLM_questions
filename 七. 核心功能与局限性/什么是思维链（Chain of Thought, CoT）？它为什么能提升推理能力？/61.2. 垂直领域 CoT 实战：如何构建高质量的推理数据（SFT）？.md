# 61.2. 垂直领域 CoT 实战：如何构建高质量的推理数据（SFT）？

> “如果要在医疗或法律等垂直领域微调一个 7B/13B 模型，单纯的问答对（Q-A）够用吗？如果训练数据中混入了‘答案正确但推理逻辑错误’的样本，会对模型产生多大的毒性？”
> —— 一位中级 AI 工程师的进阶提问

这个问题标志着你已经跨过了“Prompt Engineering”的门槛，进入了“Data-Centric AI”的核心地带。

对于通用大模型（如 GPT-4），Zero-Shot CoT 效果已经很好；但对于中小参数规模（<13B）的垂直领域模型，**CoT 能力往往不是“涌现”出来的，而是通过有监督微调（SFT）“注入”进去的。**

本文将深度剖析如何为垂直领域构建高质量的思维链训练数据。

---

## 1. 为什么 (Q, A) 已经不够了？

在传统的指令微调（Instruction Tuning）中，我们习惯了使用 `(Instruction, Output)` 的数据格式。模型学习的是输入到输出的直接映射 $P(Y|X)$。

但在需要逻辑推理的垂直领域（如诊断病情、分析合同条款），直接映射存在两个致命问题：

1.  **黑盒化**：模型可能记住了答案，但没学会逻辑。
2.  **泛化差**：遇到稍微变体的案例，模型就无法举一反三。

**CoT SFT 的核心变革**，在于将训练目标从 $P(Y|X)$ 变成了 $P(Rationale, Y|X)$。我们必须强迫模型学习中间过程 $Rationale$。

*   **普通 SFT 数据**：
    *   **Q**: 患者出现发热、颈强直、克氏征阳性，最可能的诊断是什么？
    *   **A**: 化脓性脑膜炎。
*   **CoT SFT 数据**：
    *   **Q**: ...（同上）
    *   **A**:
        1.  **分析症状**：发热提示感染；颈强直和克氏征阳性是脑膜刺激征的典型表现。
        2.  **定位病变**：脑膜刺激征提示病变累及脑膜。
        3.  **鉴别诊断**：结合感染症状和脑膜刺激征，需考虑中枢神经系统感染。
        4.  **结论**：最符合的诊断是化脓性脑膜炎。

**结论**：在垂直领域，必须构造包含 `Rationale`（推理依据）的数据。没有过程的数据，训练不出有逻辑的模型。

---

## 2. 数据构造：如何生产高质量的 Rationale？

手写几万条推理过程成本极高且效率低下。工业界通用的做法是**“蒸馏”（Distillation）**。

### 2.1 黄金流水线：GPT-4 蒸馏法

1.  **准备种子数据**：收集业务场景下的真实问题（Q）和标准答案（A）。
2.  **Prompt 诱导**：构造一个强力的 System Prompt，要求 GPT-4 针对 Q 和 A 生成详细的推理步骤。
    *   *Prompt 示例*：“你是一个资深医生。请根据以下患者描述（Q）和最终诊断（A），详细写出诊断的推理过程。要求分步骤、逻辑严密。”
3.  **生成 Rationale**：让 GPT-4 补全中间的思维链。
4.  **合成数据**：将 `(Q, GPT-4生成的CoT, A)` 组合成新的训练样本。

### 2.2 进阶技巧：思维修正（Self-Correction）

有时候 GPT-4 生成的推理过程可能不够完美。
*   **做法**：再加一步。让 GPT-4 自己检查一遍生成的推理过程：“请检查上述推理是否存在逻辑漏洞？如果有，请修正。”
*   **目的**：进一步提升数据的逻辑严密性。

---

## 3. 致命陷阱：逻辑幻觉（Hallucinated Rationale）

你提到了一个非常专业的问题：**“答案正确但推理错误”的样本有多大毒性？**

**答案是：剧毒。**

如果训练数据中存在大量“瞎猫碰上死耗子”的样本（即：推理过程胡说八道，但最后蒙对了答案），模型会学到一种可怕的模式——**“编造事实（Confabulation）”**。

它会认为：“只要我想办法把话圆回来，哪怕逻辑不通，只要最后结论对了就行。”这会导致模型在上线后表现出极强的**欺骗性**——它会用一本正经的语气说出完全错误的推导，让人类用户（尤其是非专家）难以察觉。

### 如何清洗这种“毒数据”？

自动化清洗逻辑幻觉是业界的难点，以下是几种实战方案：

#### 方案 A：基于规则的校验（适用于数学/代码）
对于数学题，可以提取推理过程中的每一个算式进行校验。如果中间步骤算错了，即使最后答案对，这条数据也必须扔掉。

#### 方案 B：多路一致性过滤（Consistency Filtering）
利用 GPT-4 生成 $N$ 条推理路径（例如 $N=5$）。
*   如果 5 条路径的推理逻辑大相径庭，说明这个问题本身具有歧义或很难推导，建议丢弃。
*   保留那些推理路径相似度高且结论一致的样本。

#### 方案 C：Reward Model 评分（AI 辅助清洗）
训练一个专门的 Reward Model（或者直接用 GPT-4 打分），不仅评价答案，更要评价“推理过程是否支持答案”。
*   *Prompt 示例*：“请评估以下推理过程是否严谨地导向了最终结论？如果存在逻辑跳跃或事实错误，请打 0 分。”
*   **过滤阈值**：只保留高分样本。

---

## 4. 总结：SFT 的“数据炼金术”

对于中级工程师而言，微调垂直领域的 CoT 模型，核心工作量不在于调参（Learning Rate / Epochs），而在于**数据的治理**。

1.  **格式升级**：从 `(Q, A)` 升级为 `(Q, Rationale, A)`。
2.  **生产力**：利用 GPT-4 等强模型进行思维链蒸馏。
3.  **质检**：建立严格的过滤机制，剔除“逻辑幻觉”样本，宁缺毋滥。

**记住：给模型喂一勺“逻辑毒药”，可能需要十倍的“高质量数据”才能救回来。在 CoT 的世界里，数据的纯度（Purity）远比数量（Quantity）重要。**
