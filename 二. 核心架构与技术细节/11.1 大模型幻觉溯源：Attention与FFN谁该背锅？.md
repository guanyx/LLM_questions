# 11.1 大模型幻觉溯源：Attention 与 FFN 谁该背锅？

在上一篇中，我们将 Transformer 拆解为“观察关系”的 **Attention（注意力机制）** 和“记忆知识”的 **Feed Forward（前馈神经网络）**。

看完这些，一个直击灵魂的问题随之而来：**当大模型一本正经地胡说八道（产生幻觉，Hallucination）时，到底是哪个组件的锅？**

是因为 FFN 脑子里的知识记错了？还是 Attention 眼睛看花了？答案是：**都有可能，但它们导致的幻觉类型截然不同。**

---

## 第一类：FFN 的锅——“无中生有的记忆错乱”

正如我们之前提到的，FFN 充当了模型的 **Key-Value Memory（键值记忆）**。如果把大模型比作一个学生，FFN 就是他背下来的教科书。

### 1. 现象：事实性错误
当你问模型：“林黛玉倒拔垂杨柳的情节发生在第几回？”模型回答：“发生在第XX回。”
或者问：“爱因斯坦在2023年获得了什么奖？”模型编造了一个奖项。

### 2. 病因诊断：知识缺失或混淆
*   **知识缺失（脑子里没货）**：训练数据里压根没有这个知识点。但因为模型是基于概率预测下一个字的，FFN 学会了“句式结构”和“语言流畅度”，却没学会“事实”。它就像一个只会填空不懂内容的学生，为了让句子通顺，强行填了一个概率最高的词进去。
*   **知识混淆（记串了）**：FFN 的参数空间是有限的，大量知识被压缩存储。就像JPEG图片压缩太狠会失真一样，知识压缩太狠也会重叠。模型可能把“林黛玉”和“鲁智深”的某些特征（比如都是名著人物）存在了相近的神经元里，提取时发生了**干扰**。

### 3. 解决思路
这类幻觉是**“知识性”**的。
*   **RAG（检索增强生成）**：既然脑子（FFN）记不住或记不准，那就允许它开卷考试。外挂一个知识库，让模型先去翻书，再回答。
*   **知识编辑（Knowledge Editing）**：直接定位并修改 FFN 中存储错误知识的具体神经元权重（虽然目前还很难精准做到）。

---

## 第二类：Attention 的锅——“张冠李戴的逻辑谬误”

Attention 的作用是 **Context Mixing（上下文聚合）**。如果说 FFN 是记忆，Attention 就是理解力。

### 1. 现象：上下文关联错误
当你给模型一段长长的财报，问：“A公司去年的净利润是多少？”
文章里同时提到了 A 公司、B 公司和 C 公司。模型可能会把 B 公司的利润安在 A 公司头上。
或者在推理题中：“小明比小红高，小红比小刚高，小刚比小强高，谁最矮？”模型绕晕了，答错了。

### 2. 病因诊断：注意力分散或错误聚焦
*   **注意力分配错误（看错了人）**：Attention 机制在计算词与词的相关性时，权重分配出了问题。比如在处理“A公司的利润”时，Attention 错误地给了“B公司”这个词更高的权重，导致信息聚合时“张冠李戴”。
*   **长距离衰减（忘性大）**：虽然 Attention 理论上能看全局，但在实际超长文本中，距离越远，注意力的聚焦能力往往越弱。关键约束条件如果藏在文章开头，模型读到结尾时可能已经“忽略”了那个条件。
*   **雪崩效应**：Attention 是逐层传递的。第一层看错了一点点，经过几十层的叠加，偏差被无限放大，最终导致逻辑崩盘。

### 3. 解决思路
这类幻觉是**“逻辑性”**或**“关联性”**的。
*   **FlashAttention / Long Context 优化**：提升模型处理长文本的能力，确保远距离的依赖也能被精准捕捉。
*   **CoT（思维链）**：让模型一步步思考。这本质上是在强迫 Attention 机制**分步聚焦**，不要试图一口气吃成胖子，而是每一步只关注当前最相关的逻辑环节。

---

## 总结：如何一眼识破？

我们可以用一个粗略的经验法则来判断幻觉的来源：

1.  **如果模型在“瞎编事实”**（比如捏造论文、虚构历史事件、算错常数）：
    *   👉 更有可能是 **FFN** 的问题（知识没存进去，或者存糊涂了）。
    *   💊 **药方**：外挂知识库 (RAG)。

2.  **如果模型在“逻辑混乱”**（比如无法遵循复杂的指令、把阅读理解里的对象搞混、忽略了你的否定词）：
    *   👉 更有可能是 **Attention** 的问题（没看清上下文的关系，注意力没对焦）。
    *   💊 **药方**：优化提示词 (Prompt Engineering)，使用思维链 (CoT)，或者缩短输入长度。

理解了这一点，作为工程师的你，在面对模型 Bug 时，就不再是盲目地调整参数，而是能像医生一样，对症下药了。
